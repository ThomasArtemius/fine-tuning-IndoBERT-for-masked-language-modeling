{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8631452,"sourceType":"datasetVersion","datasetId":5168255}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Setup and Imports\nfrom transformers import (\n    AutoModelForMaskedLM,\n    AutoTokenizer,\n    DataCollatorForLanguageModeling,\n    Trainer,\n    TrainingArguments\n)\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\nimport torch\nfrom accelerate import Accelerator\nimport math\nfrom huggingface_hub import notebook_login\n\n# 2. Initialize Model and Tokenizer (Global Scope)\nmodel_checkpoint = \"indobenchmark/indobert-base-p2\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n\n# 3. Data Preparation\ndef load_and_preprocess_data(file_path):\n    df = pd.read_csv(file_path)\n    dataset = Dataset.from_pandas(df[['Context', 'Response']].dropna())\n    return dataset.train_test_split(test_size=0.1, seed=42)\n\n# 4. Tokenization\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"Context\"],\n        truncation=True,\n        max_length=128,\n        padding=\"max_length\",\n        return_special_tokens_mask=True\n    )\n\n# 5. Training Function (Fixed)\ndef train_with_accelerate(train_dataset, eval_dataset, model, batch_size=64, epochs=5):\n    accelerator = Accelerator()\n    \n    # DataLoaders\n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer,\n        mlm_probability=0.20\n    )\n    train_dataloader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, collate_fn=data_collator\n    )\n    eval_dataloader = torch.utils.data.DataLoader(\n        eval_dataset, batch_size=batch_size, collate_fn=data_collator\n    )\n    \n    # Prepare with Accelerator\n    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n        model,\n        torch.optim.AdamW(model.parameters(), lr=5e-5),\n        train_dataloader,\n        eval_dataloader\n    )\n    \n    # Training Loop\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for batch in train_dataloader:\n            outputs = model(**batch)\n            loss = outputs.loss\n            accelerator.backward(loss)\n            optimizer.step()\n            optimizer.zero_grad()\n            total_loss += loss.item()\n        \n        # Evaluation\n        model.eval()\n        eval_losses = []\n        for batch in eval_dataloader:\n            with torch.no_grad():\n                outputs = model(**batch)\n                eval_losses.append(outputs.loss.item())\n        \n        print(f\"Epoch {epoch}: Perplexity = {math.exp(sum(eval_losses)/len(eval_losses)):.2f}\")\n    \n    return model\n\n# 6. Main Workflow\nif __name__ == \"__main__\":\n    # Load and preprocess data\n    dataset = load_and_preprocess_data(\"/kaggle/input/psychikadataset-7b/data.csv\")\n    \n    # Tokenize\n    tokenized_datasets = dataset.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=[\"Context\", \"Response\"]\n    )\n    \n    # Train (now passing the model explicitly)\n    trained_model = train_with_accelerate(\n        train_dataset=tokenized_datasets[\"train\"],\n        eval_dataset=tokenized_datasets[\"test\"],\n        model=model  # Pass the pre-loaded model\n    )\n    \n    # Save model\n    trained_model.save_pretrained(\"./indobert-finetuned\")\n    tokenizer.save_pretrained(\"./indobert-finetuned\")\n    print(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:02:07.180884Z","iopub.execute_input":"2025-07-18T05:02:07.181578Z","iopub.status.idle":"2025-07-18T05:17:10.769337Z","shell.execute_reply.started":"2025-07-18T05:02:07.181545Z","shell.execute_reply":"2025-07-18T05:17:10.768706Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForMaskedLM were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba782b039bc14480ad3d0e79bfe6fc53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c82126ca5774fae9f8c7cbf1b46aa93"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: Perplexity = 26.66\nEpoch 1: Perplexity = 12.64\nEpoch 2: Perplexity = 8.52\nEpoch 3: Perplexity = 7.07\nEpoch 4: Perplexity = 5.57\nModel saved successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import pipeline\nfrom tabulate import tabulate\n\n# Initialize the mask filler\nmask_filler = pipeline(\"fill-mask\", model=\"./indobert-finetuned\")\n\n# Get predictions\npredictions = mask_filler(\"Aku merasa sangat [MASK].\")\n\n# Format the output\noutput_data = []\nfor i, pred in enumerate(predictions, 1):\n    output_data.append([\n        i,\n        pred['token_str'],\n        f\"{pred['score']:.3f}\",\n        pred['sequence']\n    ])\n\n# Print as a neat table\nheaders = [\"Rank\", \"Prediction\", \"Score\", \"Complete Sentence\"]\nprint(tabulate(output_data, headers=headers, tablefmt=\"grid\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:20:47.483284Z","iopub.execute_input":"2025-07-18T05:20:47.483632Z","iopub.status.idle":"2025-07-18T05:20:47.866452Z","shell.execute_reply.started":"2025-07-18T05:20:47.483610Z","shell.execute_reply":"2025-07-18T05:20:47.865654Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"+--------+--------------+---------+------------------------------+\n|   Rank | Prediction   |   Score | Complete Sentence            |\n+========+==============+=========+==============================+\n|      1 | sedih        |   0.119 | aku merasa sangat sedih.     |\n+--------+--------------+---------+------------------------------+\n|      2 | tertekan     |   0.114 | aku merasa sangat tertekan.  |\n+--------+--------------+---------+------------------------------+\n|      3 | sendirian    |   0.058 | aku merasa sangat sendirian. |\n+--------+--------------+---------+------------------------------+\n|      4 | sakit        |   0.055 | aku merasa sangat sakit.     |\n+--------+--------------+---------+------------------------------+\n|      5 | gugup        |   0.046 | aku merasa sangat gugup.     |\n+--------+--------------+---------+------------------------------+\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Initialize both models\noriginal_model = pipeline(\"fill-mask\", model=\"indobenchmark/indobert-base-p2\")\nfinetuned_model = pipeline(\"fill-mask\", model=\"./indobert-finetuned\")\n\n# Get predictions from both models\ntext = \"Aku merasa sangat [MASK].\"\noriginal_preds = original_model(text)\nfinetuned_preds = finetuned_model(text)\n\n# Prepare comparison data\ncomparison_data = []\nfor i in range(5):\n    comparison_data.append([\n        i+1,\n        original_preds[i]['token_str'],\n        f\"{original_preds[i]['score']:.3f}\",\n        finetuned_preds[i]['token_str'],\n        f\"{finetuned_preds[i]['score']:.3f}\"\n    ])\n\n# Print comparison table\nheaders = [\n    \"Rank\",\n    \"Original Prediction\", \n    \"Original Score\",\n    \"Fine-tuned Prediction\",\n    \"Fine-tuned Score\"\n]\nprint(tabulate(comparison_data, headers=headers, tablefmt=\"grid\"))\nprint(\"\\nKey Observations:\")\nprint(\"- Fine-tuned model shows stronger confidence in emotional words ('sedih', 'tertekan')\")\nprint(\"- Original model may include more generic completions\")\nprint(\"- Score differences highlight domain adaptation benefits\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:22:45.612422Z","iopub.execute_input":"2025-07-18T05:22:45.613015Z","iopub.status.idle":"2025-07-18T05:22:46.645154Z","shell.execute_reply.started":"2025-07-18T05:22:45.612989Z","shell.execute_reply":"2025-07-18T05:22:46.644466Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForMaskedLM were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"+--------+-----------------------+------------------+-------------------------+--------------------+\n|   Rank | Original Prediction   |   Original Score | Fine-tuned Prediction   |   Fine-tuned Score |\n+========+=======================+==================+=========================+====================+\n|      1 | ##vian                |                0 | sedih                   |              0.119 |\n+--------+-----------------------+------------------+-------------------------+--------------------+\n|      2 | ##ans                 |                0 | tertekan                |              0.114 |\n+--------+-----------------------+------------------+-------------------------+--------------------+\n|      3 | gif                   |                0 | sendirian               |              0.058 |\n+--------+-----------------------+------------------+-------------------------+--------------------+\n|      4 | ##arit                |                0 | sakit                   |              0.055 |\n+--------+-----------------------+------------------+-------------------------+--------------------+\n|      5 | ##erto                |                0 | gugup                   |              0.046 |\n+--------+-----------------------+------------------+-------------------------+--------------------+\n\nKey Observations:\n- Fine-tuned model shows stronger confidence in emotional words ('sedih', 'tertekan')\n- Original model may include more generic completions\n- Score differences highlight domain adaptation benefits\n","output_type":"stream"}],"execution_count":7}]}